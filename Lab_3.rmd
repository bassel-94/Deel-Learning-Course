---
title: "R Notebook"
output: html_notebook
---

# Task - 1 - Comparative study of different classification algorithms.

This task is very similar to the one in turotial 2 task 2. We include in the comparison process the support vector machine and compare performance of classifiers with some level of repetitions. we will consider only 20 repetitions to save computation time. We will only consider the distributional setting 1 in the appendix.

```{r}
rm(list=ls())
source("functions_tutorial_2.R")
library(e1071)
library(randomForest)
library(class)

N = 20
Q = matrix(c(1,1,1,4), nrow = 2, byrow = TRUE)
lda_error = qda_error = knn_error = rf_error = svm.error = rep(0,N)

for (k in 1:N){
  #-- generate test and train data
  df_train = gen_bin_data(200,c(0,0), c(1,1), Q, Q)
  df_test = gen_bin_data(1000,c(0,0), c(1,1), Q, Q)
  
  #-- build lda and predict error
  lda.fit = lda(Y~., data = df_train)
  lda.pred = predict(lda.fit, newdata = df_test)$class
  lda_error[k] = calc_class_err(df_test$Y, lda.pred)
  
  #-- build qda and predict error
  qda.fit = qda(Y~., data = df_train)
  qda.pred = predict(qda.fit, newdata = df_test)$class
  qda_error[k] = calc_class_err(df_test$Y, qda.pred)
  
  #-- knn with restricted odd k's from 1 to 100 using LOOCV. p = 1 for leave p out cv.
  k_to_try = seq(1, nrow(df_train)/2, by = 2)
  cv_error = rep(0, length(k_to_try))
  for (i in seq_along(k_to_try)) {
    knn.cv.pred = knn.cv(train = df_train[, c(1:2)], 
                      cl = df_train$Y,
                      p = 1,
                      k = k_to_try[i])
    cv_error[i] = calc_class_err(df_test$Y, knn.cv.pred)
    
  }
  
  #-- choose best k (only one k) and make prediction
  best_k = min(k_to_try[which(cv_error == min(cv_error))])
  knn.pred = knn(train = df_train[,-3], 
                 test = df_test[,-3], 
                 cl = df_train$Y, 
                 k = best_k)
  knn_error[k] = calc_class_err(df_test$Y, knn.pred)
  
  #-- Random forest classifier.
  rf.fit = randomForest(Y~., data = df_train)
  rf.pred = predict(rf.fit, newdata = df_test)
  rf_error[k] = calc_class_err(df_test$Y, rf.pred)
  
  #-- Support Vector Machine classifier without any tuning
  svm.fit = svm(Y~., data = df_train, type = "C-classification")
  Y_pred = predict(svm.fit, newdata = df_test)
  svm.error[k] = calc_class_err(df_test$Y, Y_pred) 
}
```

```{r}
df_error = data.frame(lda_error = lda_error, qda_error = qda_error, knn_error = knn_error, rf_error = rf_error, svm_error = svm.error)

#-- plot boxplots of results using ggplot
library(ggplot2)
library(tidyr)
df_plot = gather(df_error, Model, ErrorValue)
ggplot(df_plot, aes(x=reorder(Model,ErrorValue), y = ErrorValue)) + 
  geom_boxplot() + 
  theme_bw() + 
  ggtitle("Comparing error for multiple classifiers inclusing svm") + 
  theme(axis.text.x = element_text(angle = 45)) + 
  labs(x = 'Classifier', y = "Classification error")

#-- show table summarizing all average error values of the classifiers in %
data.frame(ErrorValue = apply(df_error,2, mean))
```

We notice that there is no significant improvement when using support vector machines compared to the linear discriminant analysis.
To avoid repeating the task, i will not do distributional setting 2.

# Task - 2 - Classification of written digits

The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The 784 columns apart from the label consist of  28*28 matrix describing the scanned image of the digits. The digits have been size-normalized and centered in a fixed-size image. To read the minst data, we need a special reading format. 

## Reading the images

```{r}
#-- read file
to.read = file("Minst_data/t10k-images.idx3-ubyte", "rb")
#-- magic number
readBin(to.read, integer(), n=1, endian="big")
#-- number of images
readBin(to.read, integer(), n=1, endian="big")
#-- number of rows and number of columns are the same 28x28 matrix
readBin(to.read, integer(), n=1, endian="big")
```

```{r}
#-- now we need to loop and read 28*28 byte chunks into matrices, we start again.
to.read = file("Minst_data/t10k-images.idx3-ubyte", "rb")
readBin(to.read, integer(), n=4, endian="big")
m = matrix(readBin(to.read,integer(), size=1, n=28*28, endian="big"),28,28)
image(m)
```

```{r, warning=FALSE}
#-- we can represent a 5 by 5 picture containing the numbers
par(mfrow=c(5,5))
par(mar=c(0,0,0,0))
for(i in 1:25){
  m = matrix(readBin(to.read,integer(), size=1, n=28*28, endian="big"),28,28)
  image(m[,28:1])
}
```

## Reading the labels

```{r}
#-- read the training data
f = file("Minst_data/t10k-labels.idx1-ubyte", "rb")
readBin(f, integer(), n=1, endian="big")

#-- Read Number of Labels
n = readBin(f,'integer',n=1,size=4,endian='big')
#-- Read All the Labels
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
#-- See if the first letter is "7"
y[1]
```

```{r}
# Display first 25 labels
mlabel=t(matrix(y[2:26],5,5))
mlabel
```

## Function to read training and test sets (both images and labels)

```{r, warning=FALSE}
load_image_file <- function(filename) {
   ret = list()
    f = file(filename,'rb')
    readBin(f,'integer',n=1,size=4,endian='big')
    ret$n = readBin(f,'integer',n=1,size=4,endian='big')
    nrow = readBin(f,'integer',n=1,size=4,endian='big')
    ncol = readBin(f,'integer',n=1,size=4,endian='big')
    x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
    ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
    close(f)
    ret
}

load_label_file <- function(filename) {
    f = file(filename,'rb')
    readBin(f,'integer',n=1,size=4,endian='big')
    n = readBin(f,'integer',n=1,size=4,endian='big')
    y = readBin(f,'integer',n=n,size=1,signed=F)
    close(f)
    y
}

train <- load_image_file("Minst_data/train-images.idx3-ubyte")
test <- load_image_file("Minst_data/t10k-images.idx3-ubyte")

train$y <- load_label_file("Minst_data/train-labels.idx1-ubyte")
test$y <- load_label_file("Minst_data/t10k-labels.idx1-ubyte")  

class(train)
class(test)
lengths(train)
lengths(test)
```

```{r}
#-- putting data in the form of dataset
df_train = as.data.frame(train)
df_train = df_train[,-1]
df_test = as.data.frame(test)
df_test = df_test[,-1]

dim(df_train)
dim(df_test)

#-- the last column, number 785 is the label, we will rename it label
df_train[1:10,785]
names(df_test)[785] = "label"
names(df_train)[785] = "label"
```

## Data processing for the support vector machine

```{r}
#-- Convert label variable into factor

df_train$label = factor(df_train$label)
df_test$label = factor(df_test$label)
summary(df_train$label)
summary(df_test$label)
```

```{r}
#-- computation time would be unnaceptable for such a large training dataset of 10,000 rows
set.seed(100)
sample_indices = sample(1: nrow(df_train), 5000) # extracting subset of 5000 samples for modelling
train = df_train[sample_indices, ]
```

```{r}
#-- Scaling data (max pixel value is 255, we should scale it)
max(train[, !names(train)=="label"])
train[, !names(train)=="label"] = train[ , !names(train)=="label"]/255
test = cbind(label = df_test[ ,"label"], df_test[ , !names(train)=="label"]/255)
```

## Model building and evaluation

For this we will use a gaussian kernel (e.g. radial basis function)

```{r}
#-- svm using default parameters (C = box constraint = 1)
model1_rbf = ksvm(label ~ ., data = train, scaled = FALSE, kernel = "rbfdot", C = 1, gamma = 0.01)

#-- predict values for types
eval1_rbf = predict(model1_rbf, newdata = test, type = "response")

#-- Print confusion matrix and score
library(caret)
confusionMatrix(eval1_rbf, test$label)
```

After computing the svm with the recommended hyperparameters (with all the digits), we get an accuracy of 95.1%.